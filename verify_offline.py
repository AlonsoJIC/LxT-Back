"""
Script de verificaciÃ³n para asegurar que todo estÃ¡ listo para funcionamiento OFFLINE.
"""
import os
from pathlib import Path

print("=" * 70)
print("VERIFICACIÃ“N DE CONFIGURACIÃ“N OFFLINE")
print("=" * 70)

# ====== 1. VERIFICAR MODELOS DE WHISPER ======
print("\n[1/5] Verificando modelos de Whisper...")
whisper_cache = Path.home() / ".cache" / "whisper"
whisper_models = ["tiny.pt", "base.pt", "small.pt", "medium.pt", "large-v2.pt", "large-v3.pt"]

if whisper_cache.exists():
    print(f"  âœ“ Directorio de cachÃ© encontrado: {whisper_cache}")
    found_models = list(whisper_cache.glob("*.pt"))
    print(f"  â†’ Modelos encontrados: {len(found_models)}")
    for model in found_models:
        print(f"    â€¢ {model.name} ({model.stat().st_size / (1024**3):.2f} GB)")
    
    required_models = ["tiny.pt", "base.pt", "small.pt", "medium.pt"]
    missing = [m for m in required_models if not (whisper_cache / m).exists()]
    if missing:
        print(f"  âš  Modelos faltantes: {missing}")
        print(f"  â†’ Ejecuta: python download_models.py")
    else:
        print(f"  âœ“ Todos los modelos principales estÃ¡n descargados")
else:
    print(f"  âœ— ERROR: No se encontrÃ³ el directorio de cachÃ©")
    print(f"  â†’ Ejecuta: python download_models.py")

# ====== 2. VERIFICAR MODELO DE PYANNOTE ======
print("\n[2/5] Verificando modelo de Pyannote (diarizaciÃ³n)...")
hf_cache = Path.home() / ".cache" / "huggingface"

if hf_cache.exists():
    print(f"  âœ“ Directorio de HuggingFace encontrado: {hf_cache}")
    
    # Buscar modelos de pyannote (buscar en subdirectorios)
    pyannote_dirs = list(hf_cache.rglob("*pyannote*"))
    if pyannote_dirs:
        print(f"  âœ“ Encontrados {len(pyannote_dirs)} archivos/directorios de Pyannote")
        
        # Verificar modelo especÃ­fico
        speaker_diarization = list(hf_cache.rglob("*speaker-diarization-3.1*"))
        if speaker_diarization:
            print(f"  âœ“ Modelo de diarizaciÃ³n 3.1 encontrado")
        else:
            print(f"  âš  Modelo de diarizaciÃ³n 3.1 NO encontrado")
            print(f"  â†’ Ejecuta: python download_models.py")
    else:
        print(f"  âœ— No se encontraron modelos de Pyannote")
        print(f"  â†’ Ejecuta: python download_models.py")
else:
    print(f"  âœ— ERROR: No se encontrÃ³ el directorio de HuggingFace")
    print(f"  â†’ Ejecuta: python download_models.py")

# ====== 3. VERIFICAR FFMPEG ======
print("\n[3/5] Verificando FFmpeg...")
ffmpeg_exe = Path("ffmpeg.exe")
ffprobe_exe = Path("ffprobe.exe")

if ffmpeg_exe.exists():
    size_mb = ffmpeg_exe.stat().st_size / (1024**2)
    print(f"  âœ“ ffmpeg.exe encontrado ({size_mb:.1f} MB)")
else:
    print(f"  âœ— ERROR: ffmpeg.exe NO encontrado")
    print(f"  â†’ Descarga desde: https://ffmpeg.org/download.html")

if ffprobe_exe.exists():
    size_mb = ffprobe_exe.stat().st_size / (1024**2)
    print(f"  âœ“ ffprobe.exe encontrado ({size_mb:.1f} MB)")
else:
    print(f"  âœ— ERROR: ffprobe.exe NO encontrado")
    print(f"  â†’ Descarga desde: https://ffmpeg.org/download.html")

# ====== 4. VERIFICAR .ENV ======
print("\n[4/5] Verificando configuraciÃ³n (.env)...")
env_file = Path(".env")

if env_file.exists():
    print(f"  âœ“ Archivo .env encontrado")
    
    with open(env_file, 'r') as f:
        env_content = f.read()
    
    if "HF_TOKEN" in env_content:
        print(f"  âœ“ HF_TOKEN configurado")
    else:
        print(f"  âš  HF_TOKEN NO configurado (diarizaciÃ³n deshabilitada)")
    
    if "WHISPER_MODEL" in env_content:
        print(f"  âœ“ WHISPER_MODEL configurado")
else:
    print(f"  âœ— ERROR: Archivo .env NO encontrado")
    print(f"  â†’ Crea un archivo .env con HF_TOKEN")

# ====== 5. VERIFICAR PyInstaller SPEC ======
print("\n[5/5] Verificando configuraciÃ³n de build...")
spec_file = Path("transcription-backend.spec")

if spec_file.exists():
    print(f"  âœ“ Archivo .spec encontrado")
    
    with open(spec_file, 'r', encoding='utf-8') as f:
        spec_content = f.read()
    
    checks = {
        "whisper_cache": "whisper_cache" in spec_content,
        "huggingface_cache": "huggingface_cache" in spec_content,
        "ffmpeg_binaries": "ffmpeg_binaries" in spec_content or "ffmpeg.exe" in spec_content,
        "pyannote_datas": "pyannote_datas" in spec_content or "pyannote" in spec_content,
    }
    
    for check, passed in checks.items():
        status = "âœ“" if passed else "âœ—"
        print(f"  {status} {check}: {'incluido' if passed else 'FALTANTE'}")
    
    if all(checks.values()):
        print(f"  âœ“ ConfiguraciÃ³n completa para build offline")
    else:
        print(f"  âš  Revisar configuraciÃ³n del .spec")
else:
    print(f"  âœ— ERROR: Archivo .spec NO encontrado")

# ====== RESUMEN FINAL ======
print("\n" + "=" * 70)
print("RESUMEN")
print("=" * 70)

print("\nðŸ“‹ Checklist para funcionamiento OFFLINE:")
print("  [ ] Modelos de Whisper descargados (tiny, base, small, medium, large)")
print("  [ ] Modelo de Pyannote descargado (speaker-diarization-3.1)")
print("  [ ] FFmpeg y FFprobe en directorio raÃ­z")
print("  [ ] Archivo .env con HF_TOKEN configurado")
print("  [ ] Archivo .spec actualizado con todas las dependencias")

print("\nðŸš€ PrÃ³ximos pasos:")
print("  1. Si faltan modelos: python download_models.py")
print("  2. Verificar que todo estÃ¡ âœ“ arriba")
print("  3. Hacer build: pyinstaller transcription-backend.spec")
print("  4. Probar ejecutable sin conexiÃ³n a internet")

print("\nðŸ’¡ IMPORTANTE:")
print("  â€¢ Los modelos ocupan ~3-5 GB en total")
print("  â€¢ El build final serÃ¡ de ~1.5-2 GB")
print("  â€¢ AsegÃºrate de tener suficiente espacio en disco")
print()
